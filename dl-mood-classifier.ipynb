{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Music-Mood Classifier (CSI 4106 - Project - Group 29)\n",
    "# Afrah Ali - 300049798 - aali179@uottawa.ca \n",
    "# Ribhav Khosla - 300087647 - rkhos052@uottawa.ca \n",
    "# Zain Malik - 300071476 - zmali081@uottawa.ca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 17300), started 0:00:44 ago. (Use '!kill 17300' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9bf94c70e0017722\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9bf94c70e0017722\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as python_random\n",
    "import shutil\n",
    "import os\n",
    "import datetime\n",
    "from PIL import Image\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# for reproducibility purposes\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "# load tensorboard extension\n",
    "%reload_ext tensorboard\n",
    "# specify the log directory where the tensorboard logs will be written\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (260, 16)\n",
      "['acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence']\n",
      "Class distribution:\n",
      "happy        65\n",
      "sad          65\n",
      "stressful    65\n",
      "calm         65\n",
      "Name: mood, dtype: int64\n",
      "          track_name               artist                track_id  \\\n",
      "0        Upside Down         Jack Johnson  6shRGWCtBUOPFLFTTqXZIC   \n",
      "1        Someone New               Hozier  0efT4YKQLQx2YHbp6vgRX8   \n",
      "2       Little Talks  Of Monsters and Men  3a2tuvXCHbW5nuUckuHkKT   \n",
      "3    Heart's Content       Brandi Carlile  0pegFWSUOTiG0sLVEfxtvA   \n",
      "4     Sunday Morning             Maroon 5  4T5cqerbDXueYSVfXkIITo   \n",
      "..               ...                  ...                     ...   \n",
      "255    am ersten Tag       Hugo Vanbrooke  2gwhISMkdlhEqEP60P93Z1   \n",
      "256    Amour naturel       Massimo Pavoni  39bh8hsTP2ZBQWH0E308rT   \n",
      "257      Dawn Of Day          Sarah Seing  635M2GuMSoVunGBe7D7vWz   \n",
      "258         Luminous     Ludovico Einaudi  5RWA30VaTsYkFrkzxKL3aK   \n",
      "259     In The Stars        Rebecca Woods  2hxaiA9EtXjMlXhG6SCoW8   \n",
      "\n",
      "     acousticness  danceability   energy  instrumentalness  key  liveness  \\\n",
      "0          0.2380         0.787  0.65500          0.000171    6    0.1380   \n",
      "1          0.4270         0.446  0.53300          0.000003    7    0.3320   \n",
      "2          0.0206         0.445  0.75700          0.000000    1    0.1460   \n",
      "3          0.7240         0.564  0.20900          0.000040    3    0.1070   \n",
      "4          0.0756         0.604  0.76100          0.000000    0    0.0620   \n",
      "..            ...           ...      ...               ...  ...       ...   \n",
      "255        0.9880         0.238  0.02600          0.914000    3    0.1010   \n",
      "256        0.9920         0.351  0.00504          0.948000    0    0.0921   \n",
      "257        0.9750         0.394  0.09980          0.931000    2    0.1120   \n",
      "258        0.9920         0.307  0.00229          0.931000    1    0.0980   \n",
      "259        0.9880         0.397  0.00375          0.957000    9    0.1150   \n",
      "\n",
      "     loudness  mode  speechiness    tempo  time_signature  valence  mood  \n",
      "0      -8.339     0       0.0431  102.485               4   0.6500     1  \n",
      "1      -5.955     1       0.0460  183.810               4   0.5800     1  \n",
      "2      -5.177     1       0.0322  102.878               4   0.4210     1  \n",
      "3      -8.922     1       0.0317  109.024               4   0.4020     1  \n",
      "4      -5.227     1       0.0468   88.040               4   0.7870     1  \n",
      "..        ...   ...          ...      ...             ...      ...   ...  \n",
      "255   -32.656     0       0.0466   64.118               3   0.1690     0  \n",
      "256   -31.773     1       0.0386   97.071               4   0.0717     0  \n",
      "257   -29.231     1       0.0321  100.498               4   0.1500     0  \n",
      "258   -34.977     1       0.0519   67.775               5   0.2810     0  \n",
      "259   -38.226     1       0.0393   64.443               3   0.1100     0  \n",
      "\n",
      "[260 rows x 16 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "255    0\n",
      "256    0\n",
      "257    0\n",
      "258    0\n",
      "259    0\n",
      "Name: mood, Length: 260, dtype: int32\n",
      "Shape of training feature: (208, 12)\n",
      "Shape of testing feature: (52, 12)\n",
      "Shape of training label: (208,)\n",
      "Shape of training label: (52,)\n",
      "Features with notable correlation: \n",
      "energy and acousticness = -0.7810420763557123\n",
      "loudness and acousticness = -0.5988076765335911\n",
      "loudness and energy = 0.7580720435262728\n",
      "loudness and instrumentalness = -0.6368423805926942\n",
      "valence and danceability = 0.6017545622868735\n",
      "valence and energy = 0.537808418082783\n",
      "Mean energy for happy songs: nan\n",
      "Mean energy for calm songs: nan\n",
      "Mean energy for stressful songs: nan\n",
      "Mean energy for sad songs: nan\n",
      "Class distribution of train set:  0    53\n",
      "1    52\n",
      "3    52\n",
      "2    51\n",
      "Name: mood, dtype: int64\n",
      "Class distribution of test set:  2    14\n",
      "3    13\n",
      "1    13\n",
      "0    12\n",
      "Name: mood, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "# print the dimensionality of the dataframe (1)\n",
    "print('Dataframe shape: ', df.shape)\n",
    "# print the names of the columns that can be used as features when training the machine learning model (1)\n",
    "# dropping non-features\n",
    "dataset = df.drop(columns=['mood', 'track_name', 'artist', 'track_id'])\n",
    "columns = list(dataset.columns)\n",
    "print(columns)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(df['mood'].value_counts())\n",
    "\n",
    "#Label encoder\n",
    "le = LabelEncoder()\n",
    "df['mood_N'] = le.fit_transform(df['mood'])\n",
    "df = df.drop(columns=['mood'])\n",
    "df = df.rename(columns={'mood_N': 'mood'})\n",
    "print(df)\n",
    "\n",
    "# split dataset for training and testing\n",
    "target = df['mood']\n",
    "print(target)\n",
    "# Set Training and Testing Data as 8:2\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset , target, \n",
    "                                                    shuffle = True, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1)\n",
    "# Show the Training and Testing Data\n",
    "print('Shape of training feature:', x_train.shape)\n",
    "print('Shape of testing feature:', x_test.shape)\n",
    "print('Shape of training label:', y_train.shape)\n",
    "print('Shape of training label:', y_test.shape)\n",
    "\n",
    "# By analysing the features, the feature that has the closest rough approximation of Gaussian distribution is the danceability feature\n",
    "dataset[\"danceability\"].hist()\n",
    "\n",
    "# identify features that represent a notable correlation (i.e., either positive or negative correlation below or above -0.5 and 0.5) (3)\n",
    "# TODO: possibly drop correlated features\n",
    "print(\"Features with notable correlation: \")\n",
    "all_corr = dataset.corr()\n",
    "for i in range(len(all_corr)):\n",
    "    for j in range(i):\n",
    "        if all_corr.iloc[i, j] > 0.5 or all_corr.iloc[i, j] < -0.5:\n",
    "            print(str(all_corr.columns[i]) + \" and \" + str(all_corr.columns[j]) + \" = \" + str(all_corr.iloc[i, j]))\n",
    "\n",
    "# Comparing energy values across moods\n",
    "print(\"Mean energy for happy songs:\", df.loc[df['mood'] == 'happy']['energy'].mean())\n",
    "print(\"Mean energy for calm songs:\", df.loc[df['mood'] == 'calm']['energy'].mean())\n",
    "print(\"Mean energy for stressful songs:\", df.loc[df['mood'] == 'stressful']['energy'].mean())\n",
    "print(\"Mean energy for sad songs:\", df.loc[df['mood'] == 'sad']['energy'].mean())\n",
    "\n",
    "# Proportional class distribution\n",
    "\n",
    "print(\"Class distribution of train set: \", y_train.value_counts())\n",
    "print(\"Class distribution of test set: \", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 12)]              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               3328      \n",
      "_________________________________________________________________\n",
      "MoodOutput (Dense)           (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 4,356\n",
      "Trainable params: 4,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 1s 34ms/step - loss: 3.6752 - accuracy: 0.2792\n",
      "INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 1.8028 - accuracy: 0.3281\n",
      "INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.7393 - accuracy: 0.3002\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5098 - accuracy: 0.3154\n",
      "INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5508 - accuracy: 0.3778\n",
      "INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.8450 - accuracy: 0.2934\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 2.1150 - accuracy: 0.2602\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 748us/step - loss: 1.3724 - accuracy: 0.3390\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1409 - accuracy: 0.4998\n",
      "INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1527 - accuracy: 0.4913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21e1afe12b0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify the batch size hyperparameter. You can experiment with different batch sizes\n",
    "batch_size = 16\n",
    "\n",
    "# specify the model input with the required shape \n",
    "inputs = keras.Input(shape=(12,)) # 12 features\n",
    "\n",
    "# The shared layers\n",
    "intermediate = layers.Dense(256, activation='relu')(inputs)\n",
    "outputs = layers.Dense(4, activation='softmax', name='MoodOutput')(intermediate)\n",
    "\n",
    "# create the model with the required input and the outputs.\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# print the model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Instantiate the optimizer with the learning rate\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "\n",
    "# compile the model with the optimizer, loss and the metrics\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ModelCheckpoint\n",
    "# monitor validation loss and save the best model weights\n",
    "checkpoints=keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(os.path.curdir, 'models'),\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "# Initiallize TensorBoard\n",
    "tensorboard=keras.callbacks.TensorBoard(\n",
    "    log_dir=os.path.join(os.path.curdir, 'logs'),\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "# reduce the learning rate by a factor of 0.1 after waiting for 2 epochs while monitoring validation loss\n",
    "# specify a minimum learning rate to be used\n",
    "reduce_lr=keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='accuracy',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# fit the model with training and validation generators\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y= y_train,\n",
    "    epochs=10,\n",
    "    batch_size=batch_size,\n",
    "    steps_per_epoch=len(x_train)/batch_size,\n",
    "    callbacks=[reduce_lr, checkpoints, tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000021E19DE9670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1229 - accuracy: 0.5385\n"
     ]
    }
   ],
   "source": [
    "# evaluate the trained model using the test generator\n",
    "test_evaluation = model.evaluate(x_test, y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000021E197C5A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "     acousticness  danceability   energy  instrumentalness  key  liveness  \\\n",
      "102      0.578000        0.6040  0.36600          0.000000    5    0.1330   \n",
      "245      0.955000        0.0834  0.16300          0.974000    8    0.1100   \n",
      "194      0.247000        0.2060  0.23100          0.850000   11    0.0968   \n",
      "117      0.785000        0.4470  0.39300          0.000000    5    0.2800   \n",
      "190      0.000716        0.3030  0.91300          0.227000   11    0.1130   \n",
      "219      0.592000        0.3420  0.29400          0.674000    2    0.0944   \n",
      "78       0.198000        0.5480  0.42000          0.000004    0    0.0899   \n",
      "257      0.975000        0.3940  0.09980          0.931000    2    0.1120   \n",
      "127      0.178000        0.3890  0.66500          0.000732    0    0.1160   \n",
      "107      0.691000        0.3800  0.33900          0.000000    3    0.1200   \n",
      "27       0.057000        0.6950  0.65600          0.000000    1    0.2670   \n",
      "259      0.988000        0.3970  0.00375          0.957000    9    0.1150   \n",
      "39       0.007010        0.5780  0.86600          0.000000    1    0.2570   \n",
      "85       0.969000        0.5450  0.36600          0.267000    2    0.6410   \n",
      "62       0.332000        0.6210  0.82000          0.000000   10    0.1040   \n",
      "90       0.385000        0.5090  0.53800          0.000000    7    0.1040   \n",
      "4        0.075600        0.6040  0.76100          0.000000    0    0.0620   \n",
      "51       0.002050        0.6380  0.92400          0.000175    7    0.1490   \n",
      "123      0.199000        0.5520  0.60300          0.000000    8    0.1510   \n",
      "186      0.604000        0.1120  0.24800          0.956000    7    0.1100   \n",
      "223      0.964000        0.3400  0.01730          0.958000    0    0.1180   \n",
      "140      0.006370        0.4050  0.89700          0.000002    2    0.2660   \n",
      "116      0.837000        0.6810  0.17400          0.000034    1    0.0983   \n",
      "44       0.037100        0.7640  0.70500          0.000019    3    0.0943   \n",
      "38       0.011600        0.5960  0.86900          0.173000   10    0.0678   \n",
      "249      0.365000        0.7270  0.73900          0.001370    8    0.1610   \n",
      "34       0.099800        0.7430  0.65900          0.000280   10    0.0622   \n",
      "12       0.021500        0.5230  0.68700          0.000003    7    0.2030   \n",
      "73       0.346000        0.5740  0.65100          0.000000    7    0.1490   \n",
      "251      0.693000        0.6400  0.32100          0.030700    0    0.1140   \n",
      "106      0.528000        0.3310  0.34100          0.000000    9    0.1090   \n",
      "252      0.529000        0.6600  0.31600          0.000294    3    0.1040   \n",
      "114      0.883000        0.6690  0.30800          0.000000   11    0.0984   \n",
      "58       0.121000        0.6740  0.42800          0.000000    7    0.1320   \n",
      "195      0.993000        0.3350  0.00501          0.919000    1    0.0618   \n",
      "173      0.004050        0.2520  0.37800          0.939000    1    0.4690   \n",
      "233      0.598000        0.7440  0.61900          0.003720    0    0.2310   \n",
      "232      0.112000        0.6530  0.52400          0.000000   11    0.2030   \n",
      "163      0.098800        0.8520  0.54900          0.000001   10    0.1220   \n",
      "95       0.974000        0.4670  0.15700          0.000001   11    0.0816   \n",
      "230      0.970000        0.5780  0.28800          0.633000    5    0.1250   \n",
      "118      0.839000        0.5670  0.26700          0.000001    4    0.0890   \n",
      "167      0.112000        0.6460  0.83300          0.000462   11    0.1210   \n",
      "132      0.061500        0.6530  0.68400          0.000387    7    0.2700   \n",
      "31       0.429000        0.4430  0.53300          0.000004    7    0.3320   \n",
      "18       0.189000        0.8130  0.60100          0.000200   11    0.4260   \n",
      "159      0.364000        0.7020  0.60700          0.026300    2    0.1230   \n",
      "171      0.948000        0.2070  0.35300          0.889000    7    0.2530   \n",
      "188      0.008290        0.7380  0.84300          0.869000   10    0.1810   \n",
      "19       0.156000        0.6820  0.68300          0.000023    8    0.2730   \n",
      "184      0.401000        0.4350  0.38200          0.956000    1    0.0641   \n",
      "130      0.073500        0.6090  0.67400          0.060000   10    0.3450   \n",
      "\n",
      "     loudness  mode  speechiness    tempo  time_signature  valence  \n",
      "102    -7.519     1       0.0282  141.981               4   0.1300  \n",
      "245   -19.445     1       0.0511   69.002               4   0.0328  \n",
      "194   -24.597     0       0.0494  140.558               4   0.0381  \n",
      "117    -8.650     1       0.0380   73.139               3   0.5640  \n",
      "190    -4.543     1       0.2000  149.291               3   0.1590  \n",
      "219   -15.989     1       0.0426   84.014               4   0.1320  \n",
      "78     -7.842     1       0.0277  128.012               4   0.1960  \n",
      "257   -29.231     1       0.0321  100.498               4   0.1500  \n",
      "127    -6.169     1       0.0644  117.055               4   0.1990  \n",
      "107    -7.885     1       0.0338  100.607               4   0.0849  \n",
      "27     -6.038     1       0.0489   90.986               4   0.3460  \n",
      "259   -38.226     1       0.0393   64.443               3   0.1100  \n",
      "39     -3.804     1       0.0619  128.038               4   0.6190  \n",
      "85     -9.510     1       0.0378   86.997               3   0.1000  \n",
      "62     -4.865     1       0.0367  144.905               4   0.4520  \n",
      "90     -7.335     1       0.0572   75.089               4   0.2440  \n",
      "4      -5.227     1       0.0468   88.040               4   0.7870  \n",
      "51     -3.887     1       0.0360  111.995               4   0.5300  \n",
      "123    -5.710     1       0.0334  139.908               4   0.2310  \n",
      "186   -17.656     0       0.0414  154.170               3   0.0309  \n",
      "223   -24.353     1       0.0406  120.092               4   0.1240  \n",
      "140    -4.533     1       0.2640  200.083               4   0.7440  \n",
      "116    -8.745     1       0.0315  112.672               4   0.2310  \n",
      "44     -5.279     0       0.0278  101.003               4   0.6720  \n",
      "38    -11.970     1       0.0370  109.902               4   0.9440  \n",
      "249    -3.805     1       0.0411   93.005               4   0.5330  \n",
      "34     -6.755     1       0.0343  114.033               4   0.8040  \n",
      "12     -5.601     1       0.1050   90.036               4   0.7110  \n",
      "73     -7.585     1       0.0460  140.017               4   0.3680  \n",
      "251   -14.604     1       0.0931  145.045               4   0.1770  \n",
      "106    -6.057     0       0.0309  109.821               4   0.1520  \n",
      "252   -11.567     0       0.0364   91.207               4   0.5430  \n",
      "114   -10.068     1       0.0290   64.934               4   0.5200  \n",
      "58     -9.504     1       0.1220   84.878               4   0.3370  \n",
      "195   -33.366     1       0.0451  132.085               3   0.0383  \n",
      "173   -15.310     1       0.0393  114.955               4   0.0351  \n",
      "233    -9.805     1       0.0390  112.997               4   0.6410  \n",
      "232    -9.016     0       0.0502   83.970               4   0.5530  \n",
      "163    -7.310     0       0.3170  162.027               4   0.6660  \n",
      "95     -9.649     1       0.0336  108.130               4   0.2770  \n",
      "230   -17.204     1       0.0589   94.983               4   0.2760  \n",
      "118    -6.502     1       0.0299  110.011               4   0.0592  \n",
      "167    -5.134     1       0.0570  108.003               4   0.2780  \n",
      "132    -7.052     0       0.1990  110.049               4   0.3550  \n",
      "31     -5.956     1       0.0473  183.791               4   0.5960  \n",
      "18     -7.552     0       0.1160  118.981               4   0.8550  \n",
      "159    -6.509     1       0.0405  116.961               4   0.4360  \n",
      "171   -18.726     0       0.0298   84.755               4   0.3460  \n",
      "188    -4.230     0       0.0292  110.005               4   0.4440  \n",
      "19     -6.444     0       0.0287  120.023               4   0.6400  \n",
      "184   -17.059     1       0.0502  119.990               4   0.0930  \n",
      "130    -7.388     0       0.0548   90.009               4   0.3150  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.83      0.67        12\n",
      "           1       0.45      0.77      0.57        13\n",
      "           2       0.83      0.36      0.50        14\n",
      "           3       0.50      0.23      0.32        13\n",
      "\n",
      "    accuracy                           0.54        52\n",
      "   macro avg       0.59      0.55      0.51        52\n",
      "weighted avg       0.59      0.54      0.51        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate predictions using the test generator\n",
    "test_prediction = model.predict(x_test)\n",
    "print(x_test)\n",
    "test_prediction = np.argmax(test_prediction, axis=1)\n",
    "\n",
    "# print the classification report for predicting mood\n",
    "print(classification_report(y_test, test_prediction))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
