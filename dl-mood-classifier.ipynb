{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Music-Mood Classifier (CSI 4106 - Project - Group 29)\n",
    "# Afrah Ali - 300049798 - aali179@uottawa.ca \n",
    "# Ribhav Khosla - 300087647 - rkhos052@uottawa.ca \n",
    "# Zain Malik - 300071476 - zmali081@uottawa.ca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5bf1039bc4bf11af\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5bf1039bc4bf11af\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (260, 16)\n",
      "['acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence']\n",
      "Class distribution:\n",
      "happy        65\n",
      "sad          65\n",
      "stressful    65\n",
      "calm         65\n",
      "Name: mood, dtype: int64\n",
      "          track_name               artist                track_id  \\\n",
      "0        Upside Down         Jack Johnson  6shRGWCtBUOPFLFTTqXZIC   \n",
      "1        Someone New               Hozier  0efT4YKQLQx2YHbp6vgRX8   \n",
      "2       Little Talks  Of Monsters and Men  3a2tuvXCHbW5nuUckuHkKT   \n",
      "3    Heart's Content       Brandi Carlile  0pegFWSUOTiG0sLVEfxtvA   \n",
      "4     Sunday Morning             Maroon 5  4T5cqerbDXueYSVfXkIITo   \n",
      "..               ...                  ...                     ...   \n",
      "255    am ersten Tag       Hugo Vanbrooke  2gwhISMkdlhEqEP60P93Z1   \n",
      "256    Amour naturel       Massimo Pavoni  39bh8hsTP2ZBQWH0E308rT   \n",
      "257      Dawn Of Day          Sarah Seing  635M2GuMSoVunGBe7D7vWz   \n",
      "258         Luminous     Ludovico Einaudi  5RWA30VaTsYkFrkzxKL3aK   \n",
      "259     In The Stars        Rebecca Woods  2hxaiA9EtXjMlXhG6SCoW8   \n",
      "\n",
      "     acousticness  danceability   energy  instrumentalness  key  liveness  \\\n",
      "0          0.2380         0.787  0.65500          0.000171    6    0.1380   \n",
      "1          0.4270         0.446  0.53300          0.000003    7    0.3320   \n",
      "2          0.0206         0.445  0.75700          0.000000    1    0.1460   \n",
      "3          0.7240         0.564  0.20900          0.000040    3    0.1070   \n",
      "4          0.0756         0.604  0.76100          0.000000    0    0.0620   \n",
      "..            ...           ...      ...               ...  ...       ...   \n",
      "255        0.9880         0.238  0.02600          0.914000    3    0.1010   \n",
      "256        0.9920         0.351  0.00504          0.948000    0    0.0921   \n",
      "257        0.9750         0.394  0.09980          0.931000    2    0.1120   \n",
      "258        0.9920         0.307  0.00229          0.931000    1    0.0980   \n",
      "259        0.9880         0.397  0.00375          0.957000    9    0.1150   \n",
      "\n",
      "     loudness  mode  speechiness    tempo  time_signature  valence  mood  \n",
      "0      -8.339     0       0.0431  102.485               4   0.6500     1  \n",
      "1      -5.955     1       0.0460  183.810               4   0.5800     1  \n",
      "2      -5.177     1       0.0322  102.878               4   0.4210     1  \n",
      "3      -8.922     1       0.0317  109.024               4   0.4020     1  \n",
      "4      -5.227     1       0.0468   88.040               4   0.7870     1  \n",
      "..        ...   ...          ...      ...             ...      ...   ...  \n",
      "255   -32.656     0       0.0466   64.118               3   0.1690     0  \n",
      "256   -31.773     1       0.0386   97.071               4   0.0717     0  \n",
      "257   -29.231     1       0.0321  100.498               4   0.1500     0  \n",
      "258   -34.977     1       0.0519   67.775               5   0.2810     0  \n",
      "259   -38.226     1       0.0393   64.443               3   0.1100     0  \n",
      "\n",
      "[260 rows x 16 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "255    0\n",
      "256    0\n",
      "257    0\n",
      "258    0\n",
      "259    0\n",
      "Name: mood, Length: 260, dtype: int32\n",
      "Shape of training feature: (208, 12)\n",
      "Shape of testing feature: (52, 12)\n",
      "Shape of training label: (208,)\n",
      "Shape of training label: (52,)\n",
      "Features with notable correlation: \n",
      "energy and acousticness = -0.7810420763557123\n",
      "loudness and acousticness = -0.5988076765335911\n",
      "loudness and energy = 0.7580720435262728\n",
      "loudness and instrumentalness = -0.6368423805926942\n",
      "valence and danceability = 0.6017545622868735\n",
      "valence and energy = 0.537808418082783\n",
      "Mean energy for happy songs: nan\n",
      "Mean energy for calm songs: nan\n",
      "Mean energy for stressful songs: nan\n",
      "Mean energy for sad songs: nan\n",
      "Class distribution of train set:  0    53\n",
      "1    52\n",
      "3    52\n",
      "2    51\n",
      "Name: mood, dtype: int64\n",
      "Class distribution of test set:  2    14\n",
      "3    13\n",
      "1    13\n",
      "0    12\n",
      "Name: mood, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "print('Dataframe shape: ', df.shape)\n",
    "\n",
    "# dropping non-features\n",
    "dataset = df.drop(columns=['mood', 'track_name', 'artist', 'track_id'])\n",
    "columns = list(dataset.columns)\n",
    "print(columns)\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(df['mood'].value_counts())\n",
    "\n",
    "#Label encoder\n",
    "le = LabelEncoder()\n",
    "df['mood_N'] = le.fit_transform(df['mood'])\n",
    "df = df.drop(columns=['mood'])\n",
    "df = df.rename(columns={'mood_N': 'mood'})\n",
    "print(df)\n",
    "\n",
    "# split dataset for training and testing\n",
    "target = df['mood']\n",
    "print(target)\n",
    "\n",
    "# Set Training and Testing Data as 8:2\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset, \n",
    "                                                    target, \n",
    "                                                    shuffle = True, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Show the Training and Testing Data\n",
    "print('Shape of training feature:', x_train.shape)\n",
    "print('Shape of testing feature:', x_test.shape)\n",
    "print('Shape of training label:', y_train.shape)\n",
    "print('Shape of training label:', y_test.shape)\n",
    "\n",
    "# Determine features with notable correlation\n",
    "print(\"Features with notable correlation: \")\n",
    "all_corr = dataset.corr()\n",
    "for i in range(len(all_corr)):\n",
    "    for j in range(i):\n",
    "        if all_corr.iloc[i, j] > 0.5 or all_corr.iloc[i, j] < -0.5:\n",
    "            print(str(all_corr.columns[i]) + \" and \" + str(all_corr.columns[j]) + \" = \" + str(all_corr.iloc[i, j]))\n",
    "\n",
    "# Comparing energy values across moods\n",
    "print(\"Mean energy for happy songs:\", df.loc[df['mood'] == 'happy']['energy'].mean())\n",
    "print(\"Mean energy for calm songs:\", df.loc[df['mood'] == 'calm']['energy'].mean())\n",
    "print(\"Mean energy for stressful songs:\", df.loc[df['mood'] == 'stressful']['energy'].mean())\n",
    "print(\"Mean energy for sad songs:\", df.loc[df['mood'] == 'sad']['energy'].mean())\n",
    "\n",
    "# Proportional class distribution\n",
    "print(\"Class distribution of train set: \", y_train.value_counts())\n",
    "print(\"Class distribution of test set: \", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 12)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               3328      \n",
      "_________________________________________________________________\n",
      "MoodOutput (Dense)           (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 4,356\n",
      "Trainable params: 4,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 2s 150ms/step - loss: 3.7310 - accuracy: 0.2739\n",
      "INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.5857 - accuracy: 0.2974\n",
      "INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.6099 - accuracy: 0.3282\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.4922 - accuracy: 0.3336\n",
      "INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 998us/step - loss: 1.5442 - accuracy: 0.3659\n",
      "INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.7154 - accuracy: 0.2959\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.8456 - accuracy: 0.2815\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.3906 - accuracy: 0.3460\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1.1541 - accuracy: 0.4837\n",
      "INFO:tensorflow:Assets written to: .\\models\\assets\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 997us/step - loss: 1.1726 - accuracy: 0.4407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22006a55160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size hyperparameter\n",
    "batch_size = 16\n",
    "\n",
    "# model input shape\n",
    "inputs = keras.Input(shape=(12,)) # 12 features\n",
    "\n",
    "# The shared layers\n",
    "intermediate = layers.Dense(256, activation='relu')(inputs)\n",
    "outputs = layers.Dense(4, activation='softmax', name='MoodOutput')(intermediate)\n",
    "\n",
    "# model creation\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "print(model.summary())\n",
    "\n",
    "# Instantiate the optimizer with learning rate hyperparameter\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "\n",
    "# compile the model with the optimizer, loss and the metrics\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ModelCheckpoint\n",
    "# monitor validation loss and save the best model weights\n",
    "checkpoints=keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(os.path.curdir, 'models'),\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False\n",
    ")\n",
    "\n",
    "# Initiallize TensorBoard\n",
    "tensorboard=keras.callbacks.TensorBoard(\n",
    "    log_dir=os.path.join(os.path.curdir, 'logs'),\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau\n",
    "reduce_lr=keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='accuracy',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# fitting the model \n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y= y_train,\n",
    "    epochs=10,\n",
    "    batch_size=batch_size,\n",
    "    steps_per_epoch=len(x_train)/batch_size,\n",
    "    callbacks=[reduce_lr, checkpoints, tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 997us/step - loss: 1.1209 - accuracy: 0.5577\n",
      "     acousticness  danceability   energy  instrumentalness  key  liveness  \\\n",
      "102      0.578000        0.6040  0.36600          0.000000    5    0.1330   \n",
      "245      0.955000        0.0834  0.16300          0.974000    8    0.1100   \n",
      "194      0.247000        0.2060  0.23100          0.850000   11    0.0968   \n",
      "117      0.785000        0.4470  0.39300          0.000000    5    0.2800   \n",
      "190      0.000716        0.3030  0.91300          0.227000   11    0.1130   \n",
      "219      0.592000        0.3420  0.29400          0.674000    2    0.0944   \n",
      "78       0.198000        0.5480  0.42000          0.000004    0    0.0899   \n",
      "257      0.975000        0.3940  0.09980          0.931000    2    0.1120   \n",
      "127      0.178000        0.3890  0.66500          0.000732    0    0.1160   \n",
      "107      0.691000        0.3800  0.33900          0.000000    3    0.1200   \n",
      "27       0.057000        0.6950  0.65600          0.000000    1    0.2670   \n",
      "259      0.988000        0.3970  0.00375          0.957000    9    0.1150   \n",
      "39       0.007010        0.5780  0.86600          0.000000    1    0.2570   \n",
      "85       0.969000        0.5450  0.36600          0.267000    2    0.6410   \n",
      "62       0.332000        0.6210  0.82000          0.000000   10    0.1040   \n",
      "90       0.385000        0.5090  0.53800          0.000000    7    0.1040   \n",
      "4        0.075600        0.6040  0.76100          0.000000    0    0.0620   \n",
      "51       0.002050        0.6380  0.92400          0.000175    7    0.1490   \n",
      "123      0.199000        0.5520  0.60300          0.000000    8    0.1510   \n",
      "186      0.604000        0.1120  0.24800          0.956000    7    0.1100   \n",
      "223      0.964000        0.3400  0.01730          0.958000    0    0.1180   \n",
      "140      0.006370        0.4050  0.89700          0.000002    2    0.2660   \n",
      "116      0.837000        0.6810  0.17400          0.000034    1    0.0983   \n",
      "44       0.037100        0.7640  0.70500          0.000019    3    0.0943   \n",
      "38       0.011600        0.5960  0.86900          0.173000   10    0.0678   \n",
      "249      0.365000        0.7270  0.73900          0.001370    8    0.1610   \n",
      "34       0.099800        0.7430  0.65900          0.000280   10    0.0622   \n",
      "12       0.021500        0.5230  0.68700          0.000003    7    0.2030   \n",
      "73       0.346000        0.5740  0.65100          0.000000    7    0.1490   \n",
      "251      0.693000        0.6400  0.32100          0.030700    0    0.1140   \n",
      "106      0.528000        0.3310  0.34100          0.000000    9    0.1090   \n",
      "252      0.529000        0.6600  0.31600          0.000294    3    0.1040   \n",
      "114      0.883000        0.6690  0.30800          0.000000   11    0.0984   \n",
      "58       0.121000        0.6740  0.42800          0.000000    7    0.1320   \n",
      "195      0.993000        0.3350  0.00501          0.919000    1    0.0618   \n",
      "173      0.004050        0.2520  0.37800          0.939000    1    0.4690   \n",
      "233      0.598000        0.7440  0.61900          0.003720    0    0.2310   \n",
      "232      0.112000        0.6530  0.52400          0.000000   11    0.2030   \n",
      "163      0.098800        0.8520  0.54900          0.000001   10    0.1220   \n",
      "95       0.974000        0.4670  0.15700          0.000001   11    0.0816   \n",
      "230      0.970000        0.5780  0.28800          0.633000    5    0.1250   \n",
      "118      0.839000        0.5670  0.26700          0.000001    4    0.0890   \n",
      "167      0.112000        0.6460  0.83300          0.000462   11    0.1210   \n",
      "132      0.061500        0.6530  0.68400          0.000387    7    0.2700   \n",
      "31       0.429000        0.4430  0.53300          0.000004    7    0.3320   \n",
      "18       0.189000        0.8130  0.60100          0.000200   11    0.4260   \n",
      "159      0.364000        0.7020  0.60700          0.026300    2    0.1230   \n",
      "171      0.948000        0.2070  0.35300          0.889000    7    0.2530   \n",
      "188      0.008290        0.7380  0.84300          0.869000   10    0.1810   \n",
      "19       0.156000        0.6820  0.68300          0.000023    8    0.2730   \n",
      "184      0.401000        0.4350  0.38200          0.956000    1    0.0641   \n",
      "130      0.073500        0.6090  0.67400          0.060000   10    0.3450   \n",
      "\n",
      "     loudness  mode  speechiness    tempo  time_signature  valence  \n",
      "102    -7.519     1       0.0282  141.981               4   0.1300  \n",
      "245   -19.445     1       0.0511   69.002               4   0.0328  \n",
      "194   -24.597     0       0.0494  140.558               4   0.0381  \n",
      "117    -8.650     1       0.0380   73.139               3   0.5640  \n",
      "190    -4.543     1       0.2000  149.291               3   0.1590  \n",
      "219   -15.989     1       0.0426   84.014               4   0.1320  \n",
      "78     -7.842     1       0.0277  128.012               4   0.1960  \n",
      "257   -29.231     1       0.0321  100.498               4   0.1500  \n",
      "127    -6.169     1       0.0644  117.055               4   0.1990  \n",
      "107    -7.885     1       0.0338  100.607               4   0.0849  \n",
      "27     -6.038     1       0.0489   90.986               4   0.3460  \n",
      "259   -38.226     1       0.0393   64.443               3   0.1100  \n",
      "39     -3.804     1       0.0619  128.038               4   0.6190  \n",
      "85     -9.510     1       0.0378   86.997               3   0.1000  \n",
      "62     -4.865     1       0.0367  144.905               4   0.4520  \n",
      "90     -7.335     1       0.0572   75.089               4   0.2440  \n",
      "4      -5.227     1       0.0468   88.040               4   0.7870  \n",
      "51     -3.887     1       0.0360  111.995               4   0.5300  \n",
      "123    -5.710     1       0.0334  139.908               4   0.2310  \n",
      "186   -17.656     0       0.0414  154.170               3   0.0309  \n",
      "223   -24.353     1       0.0406  120.092               4   0.1240  \n",
      "140    -4.533     1       0.2640  200.083               4   0.7440  \n",
      "116    -8.745     1       0.0315  112.672               4   0.2310  \n",
      "44     -5.279     0       0.0278  101.003               4   0.6720  \n",
      "38    -11.970     1       0.0370  109.902               4   0.9440  \n",
      "249    -3.805     1       0.0411   93.005               4   0.5330  \n",
      "34     -6.755     1       0.0343  114.033               4   0.8040  \n",
      "12     -5.601     1       0.1050   90.036               4   0.7110  \n",
      "73     -7.585     1       0.0460  140.017               4   0.3680  \n",
      "251   -14.604     1       0.0931  145.045               4   0.1770  \n",
      "106    -6.057     0       0.0309  109.821               4   0.1520  \n",
      "252   -11.567     0       0.0364   91.207               4   0.5430  \n",
      "114   -10.068     1       0.0290   64.934               4   0.5200  \n",
      "58     -9.504     1       0.1220   84.878               4   0.3370  \n",
      "195   -33.366     1       0.0451  132.085               3   0.0383  \n",
      "173   -15.310     1       0.0393  114.955               4   0.0351  \n",
      "233    -9.805     1       0.0390  112.997               4   0.6410  \n",
      "232    -9.016     0       0.0502   83.970               4   0.5530  \n",
      "163    -7.310     0       0.3170  162.027               4   0.6660  \n",
      "95     -9.649     1       0.0336  108.130               4   0.2770  \n",
      "230   -17.204     1       0.0589   94.983               4   0.2760  \n",
      "118    -6.502     1       0.0299  110.011               4   0.0592  \n",
      "167    -5.134     1       0.0570  108.003               4   0.2780  \n",
      "132    -7.052     0       0.1990  110.049               4   0.3550  \n",
      "31     -5.956     1       0.0473  183.791               4   0.5960  \n",
      "18     -7.552     0       0.1160  118.981               4   0.8550  \n",
      "159    -6.509     1       0.0405  116.961               4   0.4360  \n",
      "171   -18.726     0       0.0298   84.755               4   0.3460  \n",
      "188    -4.230     0       0.0292  110.005               4   0.4440  \n",
      "19     -6.444     0       0.0287  120.023               4   0.6400  \n",
      "184   -17.059     1       0.0502  119.990               4   0.0930  \n",
      "130    -7.388     0       0.0548   90.009               4   0.3150  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69        12\n",
      "           1       0.44      0.62      0.52        13\n",
      "           2       1.00      0.43      0.60        14\n",
      "           3       0.45      0.38      0.42        13\n",
      "\n",
      "    accuracy                           0.56        52\n",
      "   macro avg       0.62      0.57      0.56        52\n",
      "weighted avg       0.63      0.56      0.55        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model evaluation with test data\n",
    "test_evaluation = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "# model predictions\n",
    "test_prediction = model.predict(x_test)\n",
    "print(x_test)\n",
    "test_prediction = np.argmax(test_prediction, axis=1)\n",
    "\n",
    "# classification report for predicting mood\n",
    "print(classification_report(y_test, test_prediction))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
